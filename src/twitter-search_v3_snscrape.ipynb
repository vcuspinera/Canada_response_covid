{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style=\"font-family:sans-serif; text-align:center\"> \n",
    "<!--     <span style='color: pink'> Twitter analysis of </span> -->\n",
    "    <span style='color: white; font-size:100%; text-shadow: 0px 0px 15px black'> Twitter analysis of </span>\n",
    "<!--     <span style='color:#00acee'> Twitter analysis of </span> -->\n",
    "<!--     <span style=\"-webkit-text-stroke\"> Twitter analysis of</span> -->\n",
    "<!--     <span class=\"hr3\" style='color:#e40843; letter-spacing: 4px; font-size:105%'> Canada</span> -->\n",
    "    <span class=\"hr3\" style='color:#e40843; font-size:120%; text-shadow: 0px 0px 30px pink'>Canada </span> <span class=\"hr3\" style='color:gray; font-size:100%; text-shadow: 0px 0px 30px pink'>response to Covid-19</span><br>\n",
    "</h1>\n",
    "\n",
    "#### ‚Äî _Using snscrape_ ‚Äî\n",
    "\n",
    "### ‚úÖ This jupyter notebook works well!\n",
    "\n",
    "The aim of this notebook is to retrieve the tweets from March 1st until April 30th, to analyze the difference in sentiment analysis of tweets from people before and after Trudeau's [announcement of government policies facing impact of Covid-19](https://www.youtube.com/watch?v=1o-tV0A87l8&feature=youtu.be) to support small businesses and their employees.\n",
    "\n",
    "\n",
    "The **snscrape** allowed us to find old tweets (as opposed to the free version of the API from twitter, and the GetOldTweets3 library that is non-currently working). The way to download tweets with this library is well explained in Martin Beck's article _[How to Scrape Tweets With snscrape](https://medium.com/better-programming/how-to-scrape-tweets-with-snscrape-90124ed006af)_ at Medium.\n",
    "\n",
    "_Authors: Leo Cuspinera ([cuspime](https://github.com/cuspime)) and Victor Cuspinera ([vcuspinera](https://github.com/vcuspinera))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Install development version of snscrape\n",
    "# !pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git \n",
    "\n",
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "from pytz import timezone\n",
    "import json\n",
    "\n",
    "# Preprocess libraries\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates\n",
    "today = datetime.now()\n",
    "init = date.fromisoformat('2020-03-01')\n",
    "\n",
    "my_dates = list()\n",
    "for d in range(0, 61, 1):\n",
    "# for d in range(0, 1, 1):\n",
    "    aux = init + timedelta(days=d)\n",
    "    my_dates.append(aux)\n",
    "\n",
    "# twitter accounts\n",
    "accounts = (\"@JustinTrudeau\", \"@CanadianPM\",\"@Canada\", \"@GovCanHealth\")\n",
    "\n",
    "# max number of results\n",
    "max_results = 100_000\n",
    "\n",
    "#folder to save information\n",
    "my_folder = \"../tweets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and save tweets as `json` files\n",
    "‚ö†Ô∏è **Caution:** Just run this code chunk once, it takes so much time (more than couple hours) to download all the tweets. Additionally, this step downloads 244 JSON files, that in total weight 10.27 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 154 ms, sys: 175 ms, total: 329 ms\n",
      "Wall time: 1h 44min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrieving tweets with `snscrape`, by using OS library to call CLI commands in Python.\n",
    "for ac in accounts:\n",
    "    for dt in my_dates:\n",
    "        next_day = dt + timedelta(days=1)\n",
    "        os.system(\"snscrape --jsonl --max-results \" + str(max_results) + \" --since \" + \n",
    "                  dt.strftime(\"%Y-%m-%d\") + \" twitter-search '\" + ac + \" until:\" + \n",
    "                  next_day.strftime(\"%Y-%m-%d\") + \"' > \" + my_folder + ac + \n",
    "                  \"_\" + dt.strftime(\"%Y-%m-%d\") + \".json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring and merge tweets by account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with @JustinTrudeau files:\n",
      "   > date: 2020-03-01 time 0.4633\n",
      "   > date: 2020-03-02 time 0.1893\n",
      "   > date: 2020-03-03 time 0.3233\n",
      "   > date: 2020-03-04 time 0.303\n",
      "   > date: 2020-03-05 time 0.3967\n",
      "   > date: 2020-03-06 time 0.3345\n",
      "   > date: 2020-03-07 time 0.3268\n",
      "   > date: 2020-03-08 time 0.2887\n",
      "   > date: 2020-03-09 time 0.4855\n",
      "   > date: 2020-03-10 time 0.5087\n",
      "   > date: 2020-03-11 time 0.4458\n",
      "   > date: 2020-03-12 time 1.1032\n",
      "   > date: 2020-03-13 time 1.2411\n",
      "   > date: 2020-03-14 time 0.9987\n",
      "   > date: 2020-03-15 time 1.0789\n",
      "   > date: 2020-03-16 time 2.0332\n",
      "   > date: 2020-03-17 time 0.9336\n",
      "   > date: 2020-03-18 time 1.2837\n",
      "   > date: 2020-03-19 time 0.9919\n",
      "   > date: 2020-03-20 time 1.0339\n",
      "   > date: 2020-03-21 time 1.4402\n",
      "   > date: 2020-03-22 time 1.5794\n",
      "   > date: 2020-03-23 time 1.1027\n",
      "   > date: 2020-03-24 time 1.9376\n",
      "   > date: 2020-03-25 time 1.4543\n",
      "   > date: 2020-03-26 time 0.8571\n",
      "   > date: 2020-03-27 time 1.2774\n",
      "   > date: 2020-03-28 time 0.9282\n",
      "   > date: 2020-03-29 time 1.1317\n",
      "   > date: 2020-03-30 time 1.7258\n",
      "   > date: 2020-03-31 time 1.1047\n",
      "   > date: 2020-04-01 time 1.9057\n",
      "   > date: 2020-04-02 time 0.8166\n",
      "   > date: 2020-04-03 time 0.8618\n",
      "   > date: 2020-04-04 time 1.9285\n",
      "   > date: 2020-04-05 time 0.9595\n",
      "   > date: 2020-04-06 time 1.0099\n",
      "   > date: 2020-04-07 time 1.1515\n",
      "   > date: 2020-04-08 time 2.0166\n",
      "   > date: 2020-04-09 time 0.9721\n",
      "   > date: 2020-04-10 time 1.0556\n",
      "   > date: 2020-04-11 time 0.9913\n",
      "   > date: 2020-04-12 time 0.9522\n",
      "   > date: 2020-04-13 time 2.2022\n",
      "   > date: 2020-04-14 time 1.132\n",
      "   > date: 2020-04-15 time 1.1922\n",
      "   > date: 2020-04-16 time 1.0087\n",
      "   > date: 2020-04-17 time 2.2994\n",
      "   > date: 2020-04-18 time 1.0253\n",
      "   > date: 2020-04-19 time 1.0465\n",
      "   > date: 2020-04-20 time 0.8573\n",
      "   > date: 2020-04-21 time 1.454\n",
      "   > date: 2020-04-22 time 2.5316\n",
      "   > date: 2020-04-23 time 1.1408\n",
      "   > date: 2020-04-24 time 1.1802\n",
      "   > date: 2020-04-25 time 0.7881\n",
      "   > date: 2020-04-26 time 1.0021\n",
      "   > date: 2020-04-27 time 1.0022\n",
      "   > date: 2020-04-28 time 1.0921\n",
      "   > date: 2020-04-29 time 2.4113\n",
      "   > date: 2020-04-30 time 1.0683\n",
      "@JustinTrudeau DB ready, time 68.3697\n",
      "@JustinTrudeau tweets saved as .JSON file, time 68.3701\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with @CanadianPM files:\n",
      "   > date: 2020-03-01 time 0.0776\n",
      "   > date: 2020-03-02 time 0.0394\n",
      "   > date: 2020-03-03 time 0.0288\n",
      "   > date: 2020-03-04 time 0.036\n",
      "   > date: 2020-03-05 time 0.0438\n",
      "   > date: 2020-03-06 time 0.037\n",
      "   > date: 2020-03-07 time 0.0399\n",
      "   > date: 2020-03-08 time 0.0285\n",
      "   > date: 2020-03-09 time 0.0367\n",
      "   > date: 2020-03-10 time 0.0299\n",
      "   > date: 2020-03-11 time 0.0484\n",
      "   > date: 2020-03-12 time 0.0594\n",
      "   > date: 2020-03-13 time 0.048\n",
      "   > date: 2020-03-14 time 0.0575\n",
      "   > date: 2020-03-15 time 0.0703\n",
      "   > date: 2020-03-16 time 0.0797\n",
      "   > date: 2020-03-17 time 0.0904\n",
      "   > date: 2020-03-18 time 0.0879\n",
      "   > date: 2020-03-19 time 0.0766\n",
      "   > date: 2020-03-20 time 0.0578\n",
      "   > date: 2020-03-21 time 0.0578\n",
      "   > date: 2020-03-22 time 0.0866\n",
      "   > date: 2020-03-23 time 0.076\n",
      "   > date: 2020-03-24 time 0.0704\n",
      "   > date: 2020-03-25 time 0.0743\n",
      "   > date: 2020-03-26 time 0.1188\n",
      "   > date: 2020-03-27 time 0.0752\n",
      "   > date: 2020-03-28 time 0.0785\n",
      "   > date: 2020-03-29 time 0.0987\n",
      "   > date: 2020-03-30 time 0.0703\n",
      "   > date: 2020-03-31 time 0.0825\n",
      "   > date: 2020-04-01 time 0.0696\n",
      "   > date: 2020-04-02 time 0.0718\n",
      "   > date: 2020-04-03 time 0.069\n",
      "   > date: 2020-04-04 time 0.0758\n",
      "   > date: 2020-04-05 time 0.0914\n",
      "   > date: 2020-04-06 time 0.0834\n",
      "   > date: 2020-04-07 time 0.0781\n",
      "   > date: 2020-04-08 time 0.0729\n",
      "   > date: 2020-04-09 time 0.0708\n",
      "   > date: 2020-04-10 time 0.0786\n",
      "   > date: 2020-04-11 time 0.0658\n",
      "   > date: 2020-04-12 time 0.0606\n",
      "   > date: 2020-04-13 time 0.0718\n",
      "   > date: 2020-04-14 time 0.0746\n",
      "   > date: 2020-04-15 time 0.0828\n",
      "   > date: 2020-04-16 time 0.1044\n",
      "   > date: 2020-04-17 time 0.0743\n",
      "   > date: 2020-04-18 time 0.0669\n",
      "   > date: 2020-04-19 time 0.0862\n",
      "   > date: 2020-04-20 time 0.0703\n",
      "   > date: 2020-04-21 time 0.1161\n",
      "   > date: 2020-04-22 time 0.1155\n",
      "   > date: 2020-04-23 time 0.0826\n",
      "   > date: 2020-04-24 time 0.0965\n",
      "   > date: 2020-04-25 time 0.0818\n",
      "   > date: 2020-04-26 time 0.0708\n",
      "   > date: 2020-04-27 time 0.0858\n",
      "   > date: 2020-04-28 time 0.0896\n",
      "   > date: 2020-04-29 time 0.0682\n",
      "   > date: 2020-04-30 time 0.0732\n",
      "@CanadianPM DB ready, time 4.3709\n",
      "@CanadianPM tweets saved as .JSON file, time 4.3709\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with @Canada files:\n",
      "   > date: 2020-03-01 time 0.0305\n",
      "   > date: 2020-03-02 time 0.03\n",
      "   > date: 2020-03-03 time 0.0267\n",
      "   > date: 2020-03-04 time 0.0241\n",
      "   > date: 2020-03-05 time 0.0269\n",
      "   > date: 2020-03-06 time 0.0223\n",
      "   > date: 2020-03-07 time 0.0219\n",
      "   > date: 2020-03-08 time 0.0244\n",
      "   > date: 2020-03-09 time 0.027\n",
      "   > date: 2020-03-10 time 0.0291\n",
      "   > date: 2020-03-11 time 0.032\n",
      "   > date: 2020-03-12 time 0.0289\n",
      "   > date: 2020-03-13 time 0.0368\n",
      "   > date: 2020-03-14 time 0.0319\n",
      "   > date: 2020-03-15 time 0.0436\n",
      "   > date: 2020-03-16 time 0.0503\n",
      "   > date: 2020-03-17 time 0.0427\n",
      "   > date: 2020-03-18 time 0.0361\n",
      "   > date: 2020-03-19 time 0.0304\n",
      "   > date: 2020-03-20 time 0.0313\n",
      "   > date: 2020-03-21 time 0.0321\n",
      "   > date: 2020-03-22 time 0.0305\n",
      "   > date: 2020-03-23 time 0.0417\n",
      "   > date: 2020-03-24 time 0.0334\n",
      "   > date: 2020-03-25 time 0.0336\n",
      "   > date: 2020-03-26 time 0.0346\n",
      "   > date: 2020-03-27 time 0.0328\n",
      "   > date: 2020-03-28 time 0.0367\n",
      "   > date: 2020-03-29 time 0.0349\n",
      "   > date: 2020-03-30 time 0.0321\n",
      "   > date: 2020-03-31 time 0.0326\n",
      "   > date: 2020-04-01 time 0.0307\n",
      "   > date: 2020-04-02 time 0.0337\n",
      "   > date: 2020-04-03 time 0.0351\n",
      "   > date: 2020-04-04 time 0.0386\n",
      "   > date: 2020-04-05 time 0.0407\n",
      "   > date: 2020-04-06 time 0.0384\n",
      "   > date: 2020-04-07 time 0.032\n",
      "   > date: 2020-04-08 time 1.6553\n",
      "   > date: 2020-04-09 time 0.0387\n",
      "   > date: 2020-04-10 time 0.0336\n",
      "   > date: 2020-04-11 time 0.0292\n",
      "   > date: 2020-04-12 time 0.0319\n",
      "   > date: 2020-04-13 time 0.0299\n",
      "   > date: 2020-04-14 time 0.028\n",
      "   > date: 2020-04-15 time 0.0421\n",
      "   > date: 2020-04-16 time 0.0385\n",
      "   > date: 2020-04-17 time 0.0327\n",
      "   > date: 2020-04-18 time 0.0269\n",
      "   > date: 2020-04-19 time 0.0287\n",
      "   > date: 2020-04-20 time 0.0283\n",
      "   > date: 2020-04-21 time 0.0355\n",
      "   > date: 2020-04-22 time 0.0337\n",
      "   > date: 2020-04-23 time 0.0332\n",
      "   > date: 2020-04-24 time 0.0363\n",
      "   > date: 2020-04-25 time 0.0294\n",
      "   > date: 2020-04-26 time 0.0343\n",
      "   > date: 2020-04-27 time 0.0339\n",
      "   > date: 2020-04-28 time 0.0287\n",
      "   > date: 2020-04-29 time 0.0363\n",
      "   > date: 2020-04-30 time 0.0336\n",
      "@Canada DB ready, time 3.6386\n",
      "@Canada tweets saved as .JSON file, time 3.6386\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with @GovCanHealth files:\n",
      "   > date: 2020-03-01 time 0.0231\n",
      "   > date: 2020-03-02 time 0.0236\n",
      "   > date: 2020-03-03 time 0.0226\n",
      "   > date: 2020-03-04 time 0.0231\n",
      "   > date: 2020-03-05 time 0.0255\n",
      "   > date: 2020-03-06 time 0.0247\n",
      "   > date: 2020-03-07 time 0.0207\n",
      "   > date: 2020-03-08 time 0.0232\n",
      "   > date: 2020-03-09 time 0.0292\n",
      "   > date: 2020-03-10 time 0.0271\n",
      "   > date: 2020-03-11 time 0.053\n",
      "   > date: 2020-03-12 time 0.0402\n",
      "   > date: 2020-03-13 time 0.0458\n",
      "   > date: 2020-03-14 time 0.0431\n",
      "   > date: 2020-03-15 time 0.0723\n",
      "   > date: 2020-03-16 time 0.0603\n",
      "   > date: 2020-03-17 time 0.0702\n",
      "   > date: 2020-03-18 time 0.0547\n",
      "   > date: 2020-03-19 time 0.0507\n",
      "   > date: 2020-03-20 time 0.0642\n",
      "   > date: 2020-03-21 time 0.0524\n",
      "   > date: 2020-03-22 time 0.0605\n",
      "   > date: 2020-03-23 time 0.054\n",
      "   > date: 2020-03-24 time 0.0521\n",
      "   > date: 2020-03-25 time 0.0477\n",
      "   > date: 2020-03-26 time 0.0507\n",
      "   > date: 2020-03-27 time 0.0492\n",
      "   > date: 2020-03-28 time 0.0437\n",
      "   > date: 2020-03-29 time 0.0411\n",
      "   > date: 2020-03-30 time 0.0449\n",
      "   > date: 2020-03-31 time 0.0502\n",
      "   > date: 2020-04-01 time 0.0427\n",
      "   > date: 2020-04-02 time 0.0417\n",
      "   > date: 2020-04-03 time 0.0411\n",
      "   > date: 2020-04-04 time 0.0375\n",
      "   > date: 2020-04-05 time 0.0391\n",
      "   > date: 2020-04-06 time 0.0466\n",
      "   > date: 2020-04-07 time 0.0383\n",
      "   > date: 2020-04-08 time 0.0441\n",
      "   > date: 2020-04-09 time 0.0422\n",
      "   > date: 2020-04-10 time 0.0556\n",
      "   > date: 2020-04-11 time 0.0489\n",
      "   > date: 2020-04-12 time 0.0493\n",
      "   > date: 2020-04-13 time 0.0553\n",
      "   > date: 2020-04-14 time 0.0751\n",
      "   > date: 2020-04-15 time 0.0663\n",
      "   > date: 2020-04-16 time 0.0617\n",
      "   > date: 2020-04-17 time 0.0654\n",
      "   > date: 2020-04-18 time 0.04\n",
      "   > date: 2020-04-19 time 0.0394\n",
      "   > date: 2020-04-20 time 0.0378\n",
      "   > date: 2020-04-21 time 0.0382\n",
      "   > date: 2020-04-22 time 0.0384\n",
      "   > date: 2020-04-23 time 0.0422\n",
      "   > date: 2020-04-24 time 0.0345\n",
      "   > date: 2020-04-25 time 0.0329\n",
      "   > date: 2020-04-26 time 0.0346\n",
      "   > date: 2020-04-27 time 0.0996\n",
      "   > date: 2020-04-28 time 0.0979\n",
      "   > date: 2020-04-29 time 0.0634\n",
      "   > date: 2020-04-30 time 0.067\n",
      "@GovCanHealth DB ready, time 2.8701\n",
      "@GovCanHealth tweets saved as .JSON file, time 2.8702\n",
      "- - - - - o - - - - -\n",
      "\n",
      "CPU times: user 1min 12s, sys: 6.3 s, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Columns\n",
    "my_columns = ['account', 'date', 'content', 'user', 'replyCount', 'retweetCount',\n",
    "              'likeCount', 'quoteCount', 'lang', 'sourceLabel']\n",
    "\n",
    "dict_tot = {}\n",
    "\n",
    "# # Call and concatenate the data frames\n",
    "for ac in accounts:\n",
    "    # Create an empty pandas dataframe\n",
    "    df = pd.DataFrame(columns = my_columns)\n",
    "    t0 = time.clock()\n",
    "    print(\"Start with \" + ac + \" files:\")\n",
    "\n",
    "    # Call the JSON files of tweets\n",
    "    for d in my_dates:\n",
    "        t00 = time.clock()\n",
    "        aux = pd.read_json(my_folder + ac + '_' + str(d) + '.json', lines=True)\n",
    "        aux['account'] = ac\n",
    "        df = pd.concat([df, aux[my_columns]])\n",
    "        print(\"   > date: \" + str(d) + ' time ' + str(round(time.clock() - t00, 4)))\n",
    "\n",
    "    # Save a JSON file for each account\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    dict_tot[ac] = df\n",
    "    print(ac + \" DB ready, time \" + str(round(time.clock() - t0, 4)))\n",
    "    # df.to_csv(my_folder + 'tweets_db_' + ac + '.csv')\n",
    "    print(ac + \" tweets saved as .JSON file, time \" + str(round(time.clock() - t0, 4)))\n",
    "    print(\"- - - - - o - - - - -\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all tweets in one `json` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Just run this section once: the first time you run the notebook. If you previously run this cell and you are reopening this notebook, go to the next section _**Open Json file with all tweets**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 ms, sys: 13.6 ms, total: 361 ms\n",
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tot = pd.DataFrame()\n",
    "# Concatenate all tweets\n",
    "df_tot = pd.concat([dict_tot['@Canada'], \n",
    "                    dict_tot['@CanadianPM'], \n",
    "                    dict_tot['@GovCanHealth'], \n",
    "                    dict_tot['@JustinTrudeau']])\n",
    "df_tot.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(df, column, fillna=None):\n",
    "    ret = None\n",
    "    if fillna is None:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems()))], axis=1)\n",
    "        del ret[column]\n",
    "    else:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems())).fillna(fillna)], axis=1)\n",
    "        del ret[column]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.82 s, sys: 296 ms, total: 9.11 s\n",
      "Wall time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# unpack information from user\n",
    "df_tot = unpack(df_tot, 'user')\n",
    "\n",
    "# select only the columns we wanted to save\n",
    "wanted_columns = ['account', 'date', 'content', 'replyCount', 'retweetCount', \n",
    "                  'likeCount', 'quoteCount', 'lang', 'sourceLabel', 'username', \n",
    "                  'followersCount', 'friendsCount', 'location']\n",
    "df_tot = df_tot[wanted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.97 s, sys: 704 ms, total: 7.67 s\n",
      "Wall time: 8.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save tweets as JSON file\n",
    "df_tot.to_json(my_folder + 'tweets_db.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open `json` file with all tweets\n",
    "#### üëâ Use this in case you already run the previous chunks, and you are reopening the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.87 s, sys: 2.16 s, total: 10 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Open the file\n",
    "df_tot = pd.read_json(my_folder + 'tweets_db.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess tweets\n",
    "#### ‚ö†Ô∏è This process is very slow because it changes more than 3.5 million tweets, one by one. \n",
    "Instead of running this section, we recommend to use the python script __[preprocess.py](https://github.com/vcuspinera/Canada_response_covid/blob/master/src/preprocess.py)__ by running from the terminal the next code:  \n",
    "`$ python src/preprocess.py --input_dir=tweets/ --output_dir=tweets/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, irrelevant_pos = ['SPACE'],\n",
    "              avoid_entities = ['ORG']):\n",
    "    \"\"\"\n",
    "    Function that identify sensible information and delete some of \n",
    "    these data as emails and urls.\n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list)\n",
    "        the list of text to be preprocessed\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant 'pos' tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "\n",
    "    Example\n",
    "    -------------\n",
    "    example = [\"Contact me at george23@gmail.com\",\n",
    "           \"@vcuspinera my webpage is https://vcuspinera.github.io\"]\n",
    "    preprocess(example)\n",
    "    (output:) ['contact me at',\n",
    "               'my webpage is']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    # function\n",
    "    for sent in text:\n",
    "        sent = str(sent).lower()\n",
    "\n",
    "        result_sent = []\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "        # This helps to detect names organization\n",
    "\n",
    "        for token in doc:            \n",
    "            if (token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities\n",
    "               ):\n",
    "                continue\n",
    "            else:\n",
    "                if str(token) in string.punctuation:\n",
    "                    try:\n",
    "                        result_sent[-1] = str(result_sent[-1]) + str(token)\n",
    "                    except:\n",
    "                        result_sent.append(str(token))\n",
    "                else:\n",
    "                    result_sent.append(str(token))\n",
    "        result.append(\" \".join(result_sent))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets\n",
    "df_tot['tweet'] = preprocess(df_tot['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "df_tot.drop('content', axis=1).to_json(output_dir + 'tweets_db_clean.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic analysis** and **EDA**\n",
    "\n",
    "#### üëâ [Click here](https://github.com/vcuspinera/Canada_response_covid/blob/master/src/eda.ipynb) to see the initial Data Analysis in the EDA jupyter notebook of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
