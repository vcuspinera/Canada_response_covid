{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style=\"font-family:sans-serif; text-align:center\"> \n",
    "<!--     <span style='color: pink'> Twitter analysis of </span> -->\n",
    "    <span style='color: white; font-size:100%; text-shadow: 0px 0px 15px black'> Twitter analysis of </span>\n",
    "<!--     <span style='color:#00acee'> Twitter analysis of </span> -->\n",
    "<!--     <span style=\"-webkit-text-stroke\"> Twitter analysis of</span> -->\n",
    "<!--     <span class=\"hr3\" style='color:#e40843; letter-spacing: 4px; font-size:105%'> Canada</span> -->\n",
    "    <span class=\"hr3\" style='color:#e40843; font-size:120%; text-shadow: 0px 0px 30px pink'>Canada </span> <span class=\"hr3\" style='color:gray; font-size:100%; text-shadow: 0px 0px 30px pink'>response to Covid-19</span><br>\n",
    "</h1>\n",
    "\n",
    "#### — _Using snscrape_ —\n",
    "\n",
    "### ✅ This jupyter notebook works well!\n",
    "\n",
    "The aim of this notebook is to retrieve the tweets from March 1st until April 30th, to analyze the difference in sentiment analysis of tweets from people before and after Trudeau's [announcement of government policies facing impact of Covid-19](https://www.youtube.com/watch?v=1o-tV0A87l8&feature=youtu.be) to support small businesses and their employees.\n",
    "\n",
    "\n",
    "The **snscrape** allowed us to find old tweets (as opposed to the free version of the API from twitter, and the GetOldTweets3 library that is non-currently working). The way to download tweets with this library is well explained in Martin Beck's article _[How to Scrape Tweets With snscrape](https://medium.com/better-programming/how-to-scrape-tweets-with-snscrape-90124ed006af)_ at Medium.\n",
    "\n",
    "_Authors: Leo Cuspinera ([cuspime](https://github.com/cuspime)) and Victor Cuspinera ([vcuspinera](https://github.com/vcuspinera))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Install development version of snscrape\n",
    "# !pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git \n",
    "\n",
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "from pytz import timezone\n",
    "import json\n",
    "\n",
    "# Preprocess libraries\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates\n",
    "today = datetime.now()\n",
    "init = date.fromisoformat('2020-03-01')\n",
    "\n",
    "my_dates = list()\n",
    "for d in range(0, 61, 1):\n",
    "# for d in range(0, 1, 1):\n",
    "    aux = init + timedelta(days=d)\n",
    "    my_dates.append(aux)\n",
    "\n",
    "# twitter accounts\n",
    "accounts = ('JustinTrudeau', 'CanadianPM', 'Canada', 'GovCanHealth')\n",
    "\n",
    "# max number of results\n",
    "max_results = 100_000\n",
    "\n",
    "#folder to save information\n",
    "my_folder = \"../tweets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and save tweets as `json` files\n",
    "⚠️ **Caution:** Just run this code chunk once, it takes so much time (more than couple hours) to download all the tweets. Additionally, this step downloads 244 JSON files, that in total weight 10.27 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Retrieving tweets with `snscrape`, by using OS library to call CLI commands in Python.\n",
    "# for ac in accounts:\n",
    "ac = \"JustinTrudeau\"\n",
    "for dt in my_dates:\n",
    "    next_day = dt + timedelta(days=1)\n",
    "    os.system(\"snscrape --jsonl --max-results \" + str(max_results) + \" --since \" + \n",
    "              dt.strftime(\"%Y-%m-%d\") + \" twitter-search '\" + ac + \" until:\" + \n",
    "              next_day.strftime(\"%Y-%m-%d\") + \"' > \" + my_folder + ac + \n",
    "              \"_\" + dt.strftime(\"%Y-%m-%d\") + \".json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring and merge tweets by account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with JustinTrudeau files:\n",
      "   > date: 2020-03-01 time 0.3428\n",
      "   > date: 2020-03-02 time 0.2795\n",
      "   > date: 2020-03-03 time 0.2992\n",
      "   > date: 2020-03-04 time 0.4031\n",
      "   > date: 2020-03-05 time 0.4071\n",
      "   > date: 2020-03-06 time 0.4562\n",
      "   > date: 2020-03-07 time 0.3766\n",
      "   > date: 2020-03-08 time 0.3176\n",
      "   > date: 2020-03-09 time 0.4908\n",
      "   > date: 2020-03-10 time 0.51\n",
      "   > date: 2020-03-11 time 0.511\n",
      "   > date: 2020-03-12 time 1.1962\n",
      "   > date: 2020-03-13 time 1.8521\n",
      "   > date: 2020-03-14 time 1.13\n",
      "   > date: 2020-03-15 time 1.0687\n",
      "   > date: 2020-03-16 time 1.7027\n",
      "   > date: 2020-03-17 time 1.4023\n",
      "   > date: 2020-03-18 time 1.4957\n",
      "   > date: 2020-03-19 time 1.2479\n",
      "   > date: 2020-03-20 time 1.6889\n",
      "   > date: 2020-03-21 time 1.1431\n",
      "   > date: 2020-03-22 time 1.7878\n",
      "   > date: 2020-03-23 time 1.2883\n",
      "   > date: 2020-03-24 time 2.1349\n",
      "   > date: 2020-03-25 time 1.7738\n",
      "   > date: 2020-03-26 time 1.0904\n",
      "   > date: 2020-03-27 time 1.96\n",
      "   > date: 2020-03-28 time 1.1311\n",
      "   > date: 2020-03-29 time 2.0735\n",
      "   > date: 2020-03-30 time 1.1505\n",
      "   > date: 2020-03-31 time 1.2504\n",
      "   > date: 2020-04-01 time 2.1373\n",
      "   > date: 2020-04-02 time 1.2382\n",
      "   > date: 2020-04-03 time 1.827\n",
      "   > date: 2020-04-04 time 1.1446\n",
      "   > date: 2020-04-05 time 1.0899\n",
      "   > date: 2020-04-06 time 1.2617\n",
      "   > date: 2020-04-07 time 2.399\n",
      "   > date: 2020-04-08 time 1.1481\n",
      "   > date: 2020-04-09 time 1.179\n",
      "   > date: 2020-04-10 time 1.1775\n",
      "   > date: 2020-04-11 time 2.1595\n",
      "   > date: 2020-04-12 time 1.0452\n",
      "   > date: 2020-04-13 time 1.3076\n",
      "   > date: 2020-04-14 time 1.3463\n",
      "   > date: 2020-04-15 time 2.5655\n",
      "   > date: 2020-04-16 time 1.3263\n",
      "   > date: 2020-04-17 time 1.3604\n",
      "   > date: 2020-04-18 time 1.315\n",
      "   > date: 2020-04-19 time 1.2921\n",
      "   > date: 2020-04-20 time 2.5748\n",
      "   > date: 2020-04-21 time 1.3601\n",
      "   > date: 2020-04-22 time 1.4329\n",
      "   > date: 2020-04-23 time 1.4043\n",
      "   > date: 2020-04-24 time 1.3157\n",
      "   > date: 2020-04-25 time 1.2556\n",
      "   > date: 2020-04-26 time 2.639\n",
      "   > date: 2020-04-27 time 1.2176\n",
      "   > date: 2020-04-28 time 1.365\n",
      "   > date: 2020-04-29 time 1.2361\n",
      "   > date: 2020-04-30 time 1.2159\n",
      "JustinTrudeau DB ready, time 79.3107\n",
      "JustinTrudeau tweets saved as .JSON file, time 79.311\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with CanadianPM files:\n",
      "   > date: 2020-03-01 time 0.0814\n",
      "   > date: 2020-03-02 time 0.0404\n",
      "   > date: 2020-03-03 time 0.0319\n",
      "   > date: 2020-03-04 time 0.0373\n",
      "   > date: 2020-03-05 time 0.0495\n",
      "   > date: 2020-03-06 time 0.0367\n",
      "   > date: 2020-03-07 time 0.0413\n",
      "   > date: 2020-03-08 time 0.0304\n",
      "   > date: 2020-03-09 time 0.038\n",
      "   > date: 2020-03-10 time 0.0316\n",
      "   > date: 2020-03-11 time 0.0495\n",
      "   > date: 2020-03-12 time 0.071\n",
      "   > date: 2020-03-13 time 0.05\n",
      "   > date: 2020-03-14 time 0.0639\n",
      "   > date: 2020-03-15 time 0.0762\n",
      "   > date: 2020-03-16 time 0.0835\n",
      "   > date: 2020-03-17 time 0.0992\n",
      "   > date: 2020-03-18 time 0.0977\n",
      "   > date: 2020-03-19 time 0.0802\n",
      "   > date: 2020-03-20 time 0.0625\n",
      "   > date: 2020-03-21 time 0.0635\n",
      "   > date: 2020-03-22 time 0.0912\n",
      "   > date: 2020-03-23 time 0.075\n",
      "   > date: 2020-03-24 time 0.0789\n",
      "   > date: 2020-03-25 time 0.0884\n",
      "   > date: 2020-03-26 time 0.1111\n",
      "   > date: 2020-03-27 time 0.0909\n",
      "   > date: 2020-03-28 time 0.0968\n",
      "   > date: 2020-03-29 time 0.1347\n",
      "   > date: 2020-03-30 time 0.1121\n",
      "   > date: 2020-03-31 time 0.1048\n",
      "   > date: 2020-04-01 time 0.091\n",
      "   > date: 2020-04-02 time 0.0944\n",
      "   > date: 2020-04-03 time 0.1006\n",
      "   > date: 2020-04-04 time 1.6804\n",
      "   > date: 2020-04-05 time 0.1076\n",
      "   > date: 2020-04-06 time 0.0905\n",
      "   > date: 2020-04-07 time 0.0904\n",
      "   > date: 2020-04-08 time 0.0813\n",
      "   > date: 2020-04-09 time 0.0737\n",
      "   > date: 2020-04-10 time 0.079\n",
      "   > date: 2020-04-11 time 0.0773\n",
      "   > date: 2020-04-12 time 0.0652\n",
      "   > date: 2020-04-13 time 0.0737\n",
      "   > date: 2020-04-14 time 0.0842\n",
      "   > date: 2020-04-15 time 0.0821\n",
      "   > date: 2020-04-16 time 0.1045\n",
      "   > date: 2020-04-17 time 0.0811\n",
      "   > date: 2020-04-18 time 0.0722\n",
      "   > date: 2020-04-19 time 0.0873\n",
      "   > date: 2020-04-20 time 0.0915\n",
      "   > date: 2020-04-21 time 0.1376\n",
      "   > date: 2020-04-22 time 0.1446\n",
      "   > date: 2020-04-23 time 0.114\n",
      "   > date: 2020-04-24 time 0.1159\n",
      "   > date: 2020-04-25 time 0.1049\n",
      "   > date: 2020-04-26 time 0.0922\n",
      "   > date: 2020-04-27 time 0.1047\n",
      "   > date: 2020-04-28 time 0.1007\n",
      "   > date: 2020-04-29 time 0.0731\n",
      "   > date: 2020-04-30 time 0.0737\n",
      "CanadianPM DB ready, time 6.578\n",
      "CanadianPM tweets saved as .JSON file, time 6.578\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with Canada files:\n",
      "   > date: 2020-03-01 time 1.4452\n",
      "   > date: 2020-03-02 time 3.3458\n",
      "   > date: 2020-03-03 time 1.7353\n",
      "   > date: 2020-03-04 time 4.0677\n",
      "   > date: 2020-03-05 time 2.1589\n",
      "   > date: 2020-03-06 time 3.6887\n",
      "   > date: 2020-03-07 time 1.5083\n",
      "   > date: 2020-03-08 time 1.6112\n",
      "   > date: 2020-03-09 time 4.4223\n",
      "   > date: 2020-03-10 time 2.5898\n",
      "   > date: 2020-03-11 time 2.4819\n",
      "   > date: 2020-03-12 time 5.201\n",
      "   > date: 2020-03-13 time 3.841\n",
      "   > date: 2020-03-14 time 5.4292\n",
      "   > date: 2020-03-15 time 2.7336\n",
      "   > date: 2020-03-16 time 6.7799\n",
      "   > date: 2020-03-17 time 3.2196\n",
      "   > date: 2020-03-18 time 7.207\n",
      "   > date: 2020-03-19 time 3.1048\n",
      "   > date: 2020-03-20 time 3.5831\n",
      "   > date: 2020-03-21 time 6.5514\n",
      "   > date: 2020-03-22 time 2.1579\n",
      "   > date: 2020-03-23 time 3.8096\n",
      "   > date: 2020-03-24 time 3.5377\n",
      "   > date: 2020-03-25 time 7.4603\n",
      "   > date: 2020-03-26 time 4.1484\n",
      "   > date: 2020-03-27 time 8.5782\n",
      "   > date: 2020-03-28 time 3.3937\n",
      "   > date: 2020-03-29 time 2.6247\n",
      "   > date: 2020-03-30 time 3.8481\n",
      "   > date: 2020-03-31 time 4.8007\n",
      "   > date: 2020-04-01 time 8.9316\n",
      "   > date: 2020-04-02 time 4.1741\n",
      "   > date: 2020-04-03 time 5.5723\n",
      "   > date: 2020-04-04 time 10.7284\n",
      "   > date: 2020-04-05 time 3.9394\n",
      "   > date: 2020-04-06 time 4.4791\n",
      "   > date: 2020-04-07 time 3.7067\n",
      "   > date: 2020-04-08 time 4.1113\n",
      "   > date: 2020-04-09 time 9.8495\n",
      "   > date: 2020-04-10 time 4.266\n",
      "   > date: 2020-04-11 time 4.7724\n",
      "   > date: 2020-04-12 time 4.6182\n",
      "   > date: 2020-04-13 time 4.2053\n",
      "   > date: 2020-04-14 time 4.4275\n",
      "   > date: 2020-04-15 time 32.4792\n",
      "   > date: 2020-04-16 time 5.1792\n",
      "   > date: 2020-04-17 time 6.4766\n",
      "   > date: 2020-04-18 time 4.5438\n",
      "   > date: 2020-04-19 time 5.3341\n",
      "   > date: 2020-04-20 time 68.2918\n",
      "   > date: 2020-04-21 time 5.531\n",
      "   > date: 2020-04-22 time 4.9961\n",
      "   > date: 2020-04-23 time 4.612\n",
      "   > date: 2020-04-24 time 6.4657\n",
      "   > date: 2020-04-25 time 5.7971\n",
      "   > date: 2020-04-26 time 4.5082\n",
      "   > date: 2020-04-27 time 69.1472\n",
      "   > date: 2020-04-28 time 5.9128\n",
      "   > date: 2020-04-29 time 5.6976\n",
      "   > date: 2020-04-30 time 5.3697\n",
      "Canada DB ready, time 439.2118\n",
      "Canada tweets saved as .JSON file, time 439.2122\n",
      "- - - - - o - - - - -\n",
      "\n",
      "Start with GovCanHealth files:\n",
      "   > date: 2020-03-01 time 0.1525\n",
      "   > date: 2020-03-02 time 0.0405\n",
      "   > date: 2020-03-03 time 0.0321\n",
      "   > date: 2020-03-04 time 0.0337\n",
      "   > date: 2020-03-05 time 0.0362\n",
      "   > date: 2020-03-06 time 0.0332\n",
      "   > date: 2020-03-07 time 0.0264\n",
      "   > date: 2020-03-08 time 0.026\n",
      "   > date: 2020-03-09 time 0.0352\n",
      "   > date: 2020-03-10 time 0.0432\n",
      "   > date: 2020-03-11 time 0.0694\n",
      "   > date: 2020-03-12 time 0.0517\n",
      "   > date: 2020-03-13 time 0.0653\n",
      "   > date: 2020-03-14 time 0.0531\n",
      "   > date: 2020-03-15 time 0.089\n",
      "   > date: 2020-03-16 time 0.0827\n",
      "   > date: 2020-03-17 time 0.0965\n",
      "   > date: 2020-03-18 time 0.0661\n",
      "   > date: 2020-03-19 time 0.0656\n",
      "   > date: 2020-03-20 time 0.092\n",
      "   > date: 2020-03-21 time 0.0628\n",
      "   > date: 2020-03-22 time 0.07\n",
      "   > date: 2020-03-23 time 0.0751\n",
      "   > date: 2020-03-24 time 0.0648\n",
      "   > date: 2020-03-25 time 0.061\n",
      "   > date: 2020-03-26 time 0.063\n",
      "   > date: 2020-03-27 time 0.0601\n",
      "   > date: 2020-03-28 time 0.0554\n",
      "   > date: 2020-03-29 time 0.0573\n",
      "   > date: 2020-03-30 time 0.0626\n",
      "   > date: 2020-03-31 time 0.0599\n",
      "   > date: 2020-04-01 time 0.0517\n",
      "   > date: 2020-04-02 time 0.0563\n",
      "   > date: 2020-04-03 time 0.0566\n",
      "   > date: 2020-04-04 time 0.0517\n",
      "   > date: 2020-04-05 time 0.0485\n",
      "   > date: 2020-04-06 time 0.0551\n",
      "   > date: 2020-04-07 time 0.0529\n",
      "   > date: 2020-04-08 time 0.0543\n",
      "   > date: 2020-04-09 time 0.0537\n",
      "   > date: 2020-04-10 time 0.0551\n",
      "   > date: 2020-04-11 time 0.0533\n",
      "   > date: 2020-04-12 time 0.0435\n",
      "   > date: 2020-04-13 time 0.0485\n",
      "   > date: 2020-04-14 time 0.0603\n",
      "   > date: 2020-04-15 time 0.0719\n",
      "   > date: 2020-04-16 time 0.0612\n",
      "   > date: 2020-04-17 time 0.059\n",
      "   > date: 2020-04-18 time 0.0557\n",
      "   > date: 2020-04-19 time 0.0526\n",
      "   > date: 2020-04-20 time 0.051\n",
      "   > date: 2020-04-21 time 0.0446\n",
      "   > date: 2020-04-22 time 0.0459\n",
      "   > date: 2020-04-23 time 0.0559\n",
      "   > date: 2020-04-24 time 0.0483\n",
      "   > date: 2020-04-25 time 0.0437\n",
      "   > date: 2020-04-26 time 0.0501\n",
      "   > date: 2020-04-27 time 0.1186\n",
      "   > date: 2020-04-28 time 0.1132\n",
      "   > date: 2020-04-29 time 0.0876\n",
      "   > date: 2020-04-30 time 0.0885\n",
      "GovCanHealth DB ready, time 3.6821\n",
      "GovCanHealth tweets saved as .JSON file, time 3.6821\n",
      "- - - - - o - - - - -\n",
      "\n",
      "CPU times: user 6min 8s, sys: 2min 40s, total: 8min 48s\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Columns\n",
    "my_columns = ['account', 'date', 'content', 'user', 'replyCount', 'retweetCount',\n",
    "              'likeCount', 'quoteCount', 'lang', 'sourceLabel']\n",
    "\n",
    "dict_tot = {}\n",
    "\n",
    "# # Call and concatenate the data frames\n",
    "for ac in accounts:\n",
    "    # Create an empty pandas dataframe\n",
    "    df = pd.DataFrame(columns = my_columns)\n",
    "    t0 = time.clock()\n",
    "    print(\"Start with \" + ac + \" files:\")\n",
    "\n",
    "    # Call the JSON files of tweets\n",
    "    for d in my_dates:\n",
    "        t00 = time.clock()\n",
    "        aux = pd.read_json(my_folder + ac + '_' + str(d) + '.json', lines=True)\n",
    "        aux['account'] = ac\n",
    "        df = pd.concat([df, aux[my_columns]])\n",
    "        print(\"   > date: \" + str(d) + ' time ' + str(round(time.clock() - t00, 4)))\n",
    "\n",
    "    # Save a JSON file for each account\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    dict_tot[ac] = df\n",
    "    print(ac + \" DB ready, time \" + str(round(time.clock() - t0, 4)))\n",
    "    # df.to_csv(my_folder + 'tweets_db_' + ac + '.csv')\n",
    "    print(ac + \" tweets saved as .JSON file, time \" + str(round(time.clock() - t0, 4)))\n",
    "    print(\"- - - - - o - - - - -\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all tweets in one `json` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Just run this section once: the first time you run the notebook. If you previously run this cell and you are reopening this notebook, go to the next section _**Open Json file with all tweets**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.36 s, sys: 11.7 s, total: 17 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Concatenate all tweets\n",
    "df_tot = pd.concat([dict_tot['Canada'], \n",
    "                    dict_tot['CanadianPM'], \n",
    "                    dict_tot['GovCanHealth'], \n",
    "                    dict_tot['JustinTrudeau']])\n",
    "df_tot.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(df, column, fillna=None):\n",
    "    # \n",
    "    # from https://codereview.stackexchange.com/questions/93923\n",
    "    #      /extracting-contents-of-dictionary-contained-in-pandas-dataframe-to-make-new-data\n",
    "    ret = None\n",
    "    if fillna is None:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems()))], axis=1)\n",
    "        del ret[column]\n",
    "    else:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems())).fillna(fillna)], axis=1)\n",
    "        del ret[column]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 2min 14s, total: 3min 20s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# unpack information form user\n",
    "df_tot = unpack(df_tot, 'user')\n",
    "\n",
    "# select only the columns we wanted to save\n",
    "wanted_columns = ['account', 'date', 'content', 'replyCount', 'retweetCount', \n",
    "                  'likeCount', 'quoteCount', 'lang', 'sourceLabel', 'username', \n",
    "                  'followersCount', 'friendsCount', 'location']\n",
    "df_tot = df_tot[wanted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.9 s, sys: 2min 33s, total: 3min 26s\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save tweets as JSON file\n",
    "df_tot.to_json(my_folder + 'tweets_db.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open `json` file with all tweets\n",
    "#### 👉 Use this in case you already run the previous chunks, and you are reopening the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.9 s, sys: 17.5 s, total: 1min 7s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Open the file\n",
    "df_tot = pd.read_json(my_folder + 'tweets_db.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess tweets\n",
    "#### ⚠️ This process is very slow because it changes more than 3.5 million tweets, one by one. \n",
    "Instead of running this section, we recommend to use the python script __[preprocess.py](https://github.com/vcuspinera/Canada_response_covid/blob/master/src/preprocess.py)__ by running from the terminal the next code:  \n",
    "`$ python src/preprocess.py --input_dir=tweets/ --output_dir=tweets/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, irrelevant_pos = ['SPACE'],\n",
    "              avoid_entities = ['ORG']):\n",
    "    \"\"\"\n",
    "    Function that identify sensible information and delete some of \n",
    "    these data as emails and urls.\n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list)\n",
    "        the list of text to be preprocessed\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant 'pos' tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "\n",
    "    Example\n",
    "    -------------\n",
    "    example = [\"Contact me at george23@gmail.com\",\n",
    "           \"@vcuspinera my webpage is https://vcuspinera.github.io\"]\n",
    "    preprocess(example)\n",
    "    (output:) ['contact me at',\n",
    "               'my webpage is']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    # function\n",
    "    for sent in text:\n",
    "        sent = str(sent).lower()\n",
    "\n",
    "        result_sent = []\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "        # This helps to detect names organization\n",
    "\n",
    "        for token in doc:            \n",
    "            if (token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities\n",
    "               ):\n",
    "                continue\n",
    "            else:\n",
    "                if str(token) in string.punctuation:\n",
    "                    try:\n",
    "                        result_sent[-1] = str(result_sent[-1]) + str(token)\n",
    "                    except:\n",
    "                        result_sent.append(str(token))\n",
    "                else:\n",
    "                    result_sent.append(str(token))\n",
    "        result.append(\" \".join(result_sent))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets\n",
    "df_tot['tweet'] = preprocess(df_tot['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "df_tot.drop('content', axis=1).to_json(output_dir + 'tweets_db_clean.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic analysis** and **EDA**\n",
    "\n",
    "#### 👉 [Click here](https://github.com/vcuspinera/Canada_response_covid/blob/master/src/EDA.ipynb) to see the initial Data Analysis in the EDA jupyter notebook of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
